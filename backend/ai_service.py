import os
import asyncio
import base64
from openai import OpenAI, AsyncOpenAI
from dotenv import load_dotenv
from schemas import StoryDraft

# ==========================================
# 0. í™˜ê²½ì„¤ì • ë° í´ë¼ì´ì–¸íŠ¸ ì¤€ë¹„
# ==========================================
load_dotenv() # .env íŒŒì¼ì—ì„œ API í‚¤ ë¶ˆëŸ¬ì˜¤ê¸°

# GPT í…ìŠ¤íŠ¸ ìƒì„± ë° DALL-E ì´ë¯¸ì§€ í¸ì§‘ìš© (ë™ê¸°ì‹ í´ë¼ì´ì–¸íŠ¸)
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# TTS ìŒì„± ìƒì„±ìš© (ë¹„ë™ê¸°ì‹ í´ë¼ì´ì–¸íŠ¸)
aclient = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))

TEMP_DIR = "backend/temp"
os.makedirs(TEMP_DIR, exist_ok=True)

# ==========================================
# 1. [ì´ê´„ ì…°í”„] GPT-4o ìŠ¤í† ë¦¬ & í€´ì¦ˆ ëŒ€ë³¸ ìƒì„± (Structured Outputs)
# ==========================================
def generate_story_draft(child_name: str, age: int, personality: str, emotion: str, source_text: str) -> StoryDraft:
    print("\nâ³ [GPT-4o] ë™í™” ëŒ€ë³¸ ë° ìºë¦­í„° ì„¤ì • ìƒì„± ì¤‘...")
    
    system_prompt = f"""
    ë‹¹ì‹ ì€ {age}ì‚´ ì•„ì´ë“¤ì˜ ë§ˆìŒì„ ì½ì–´ì£¼ëŠ” ìµœê³ ì˜ ë§ì¶¤í˜• ë™í™” ì‘ê°€ì´ì êµìœ¡ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
    ì•„ì´ì˜ ì´ë¦„ì€ '{child_name}'ì´ê³ , ì„±í–¥ì€ '{personality}'ì´ë©°, í˜„ì¬ ê¸°ë¶„ì€ '{emotion}' ìƒíƒœì…ë‹ˆë‹¤.
    
    ì´ ì•„ì´ë¥¼ ë‹¬ë˜ì£¼ê¸° ìœ„í•´, ì•„ë˜ì˜ [í•™ìŠµ ê°œë…]ì„ ìì—°ìŠ¤ëŸ½ê²Œ ë…¹ì—¬ë‚¸ 5ì¥ì§œë¦¬ ë™í™”ì±… ëŒ€ë³¸ì„ ì‘ì„±í•˜ì„¸ìš”.
    
    [í•™ìŠµ ê°œë…]
    {source_text}
    
    [ì‘ì„± ê·œì¹™]
    1. ì£¼ì¸ê³µì˜ ì´ë¦„ì€ ë°˜ë“œì‹œ '{child_name}'ìœ¼ë¡œ í•˜ì„¸ìš”.
    2. ì´ 5ê°œì˜ ì”¬(scene)ìœ¼ë¡œ êµ¬ì„±í•˜ì„¸ìš”. 
    3. 3ë²ˆ ì”¬ê³¼ 5ë²ˆ ì”¬ì—ëŠ” ë°˜ë“œì‹œ [í•™ìŠµ ê°œë…]ê³¼ ê´€ë ¨ëœ í€´ì¦ˆ(quiz)ë¥¼ ë„£ìœ¼ì„¸ìš”. ë‚˜ë¨¸ì§€ ì”¬ì˜ quizëŠ” nullë¡œ ë¹„ì›Œë‘ì„¸ìš”.
    4. ê° ì”¬ë§ˆë‹¤ DALL-E 3ê°€ ê·¸ë¦¼ì„ ê·¸ë¦´ ìˆ˜ ìˆë„ë¡, 'image_prompt'ë¥¼ ìƒì„¸í•œ ì˜ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”. (ìˆ˜ì±„í™” í’ì˜ ë”°ëœ»í•œ ë™í™”ì±… ìŠ¤íƒ€ì¼ì„ ë¬˜ì‚¬í•  ê²ƒ)
    5. ëª¨ë“  ë™í™” ë‚´ìš©, ëŒ€ì‚¬, í€´ì¦ˆëŠ” ë°˜ë“œì‹œ 'í•œêµ­ì–´'ë¡œ ì‘ì„±í•˜ì„¸ìš”. (ë‹¨, DALL-Eë¥¼ ìœ„í•œ image_promptì™€ style_guide ë“±ì€ ë°˜ë“œì‹œ ì˜ì–´ë¡œ ì‘ì„±í•  ê²ƒ)
    6. ì¼ê´€ëœ ê·¸ë¦¼ ìƒì„±ì„ ìœ„í•´ 'style_guide', 'character_bible', 'anchor_prompt'ë¥¼ êµ¬ì²´ì ì¸ ì˜ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”.
    """

    # GPT-4o í˜¸ì¶œ (Structured Outputs ê¸°ëŠ¥ìœ¼ë¡œ JSON í‹€ ê°•ì œ)
    completion = client.beta.chat.completions.parse(
        model="gpt-4o-2024-08-06",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": "ê·œê²©ì— ë§ì¶°ì„œ ë™í™”ì±… JSON ë°ì´í„°ë¥¼ ìƒì„±í•´ì¤˜."}
        ],
        response_format=StoryDraft, 
    )

    story_draft = completion.choices[0].message.parsed
    print(f"âœ… [GPT-4o] ëŒ€ë³¸ ìƒì„± ì™„ë£Œ! ì œëª©: {story_draft.title}")
    
    return story_draft


# ==========================================
# 2. [ë¯¸ìˆ  ê°ë…] ìºë¦­í„° ì‹œíŠ¸(Anchor Image) ìƒì„±
# ==========================================
def generate_anchor_image(anchor_prompt: str, style_guide: str, character_bible: str) -> str:
    print("ğŸ¨ [Anchor] ìºë¦­í„° ì‹œíŠ¸(ê¸°ì¤€ ì´ë¯¸ì§€) ìƒì„± ì¤‘...")
    
    full_prompt = f"""
    {style_guide}
    {character_bible}
    {anchor_prompt}
    Important: Create a character reference sheet showing the full body and face clearly.
    """
    
    try:
        response = client.images.generate(
            model="dall-e-3",
            prompt=full_prompt,
            size="1024x1024",
            quality="standard",
            n=1,
            response_format="b64_json" # íŒŒì¼ ì €ì¥ì„ ìœ„í•´ base64ë¡œ ë°›ìŒ
        )
        
        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
        image_data = base64.b64decode(response.data[0].b64_json)
        file_path = os.path.join(TEMP_DIR, "anchor.png")
        
        with open(file_path, "wb") as f:
            f.write(image_data)
            
        print("âœ… [Anchor] ìºë¦­í„° ì‹œíŠ¸ ìƒì„± ì™„ë£Œ!")
        return file_path
        
    except Exception as e:
        print(f"âŒ [Anchor] ìƒì„± ì‹¤íŒ¨: {e}")
        return ""


# ==========================================
# 3. [ë¯¸ìˆ íŒ€] ì¼ê´€ì„± ìˆëŠ” ì”¬ ì´ë¯¸ì§€ ìƒì„± (Sequential Editing)
# ==========================================
def generate_scene_image_consistent(scene_no: int, scene_prompt: str, style_guide: str, character_bible: str, anchor_path: str, prev_image_path: str = None) -> str:
    print(f"ğŸ¨ [{scene_no}ë²ˆ ì”¬] ì¼ê´€ì„± ìˆëŠ” ê·¸ë¦¼ ê·¸ë¦¬ëŠ” ì¤‘...")
    
    # í”„ë¡¬í”„íŠ¸ ì¡°í•©
    consistent_prompt = f"""
    {style_guide}
    {character_bible}
    Continuity rules: Keep the protagonist's face, hair, and outfit colors exactly the same as the reference image.
    match the watercolor texture and linework style.
    
    Scene Description:
    {scene_prompt}
    """
    
    try:
        # í¸ì§‘(Edit) ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ì—¬ ìŠ¤íƒ€ì¼ ìœ ì§€ (Anchor ì´ë¯¸ì§€ë¥¼ ë§ˆìŠ¤í¬/ë ˆí¼ëŸ°ìŠ¤ë¡œ í™œìš©í•˜ëŠ” ê°œë…)
        # ì£¼ì˜: DALL-E 3ëŠ” editì„ ì§€ì›í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ì—¬ê¸°ì„œëŠ” ë ˆí¼ëŸ°ìŠ¤ í”„ë¡¬í”„íŠ¸ë¥¼ ê°•í™”í•˜ëŠ” ì „ëµì„ ì‚¬ìš©í•˜ê±°ë‚˜
        # ì˜ˆì œ ì½”ë“œì²˜ëŸ¼ images.edit (DALL-E 2)ì„ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤. 
        # í•˜ì§€ë§Œ DALL-E 3 í’ˆì§ˆì„ ì›í•œë‹¤ë©´, í˜„ì¬ë¡œì„  í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ì— ì˜ì¡´í•˜ê±°ë‚˜ 
        # OpenAIì˜ ìµœì‹  ê¸°ëŠ¥(Seed, Reference Image ë“±)ì´ í•„ìš”í•©ë‹ˆë‹¤.
        # *ì‚¬ìš©ìì˜ ìš”ì²­ì— ë”°ë¼ ì œê³µëœ 'deoha' ì½”ë“œì˜ ë¡œì§(images.edit)ì„ ë”°ë¦…ë‹ˆë‹¤.*
        
        # ì´ë¯¸ì§€ íŒŒì¼ ì—´ê¸°
        img_files = [open(anchor_path, "rb")]
        if prev_image_path:
            img_files.append(open(prev_image_path, "rb"))
            
        # ì‹¤ì œë¡œëŠ” images.editì´ ë§ˆìŠ¤í¬ë¥¼ ìš”êµ¬í•˜ê±°ë‚˜, ëª¨ë¸ì´ dall-e-2ì—¬ì•¼ í•˜ëŠ” ì œì•½ì´ ìˆì„ ìˆ˜ ìˆìŒ.
        # ì—¬ê¸°ì„œëŠ” ì œê³µëœ ì½”ë“œì˜ ë¡œì§ì„ ìµœëŒ€í•œ ìˆ˜ìš©í•˜ë˜, ëª¨ë¸ì€ í˜¸í™˜ì„±ì„ ê³ ë ¤í•´ì•¼ í•¨.
        # ë§Œì•½ dall-e-3ê°€ editì„ ì§€ì›í•˜ì§€ ì•Šìœ¼ë©´ generateë¡œ ìš°íšŒí•´ì•¼ í•¨.
        
        # [ì „ëµ ìˆ˜ì •] DALL-E 3ëŠ” editì„ ì§€ì›í•˜ì§€ ì•ŠìŒ. 
        # ì‚¬ìš©ìê°€ ì¤€ ì½”ë“œëŠ” 'gpt-image-1.5'ë¼ëŠ” ê°€ìƒì˜ ëª¨ë¸ì„ ì‚¬ìš©í•˜ê³  ìˆì—ˆìŒ.
        # í˜„ì‹¤ì ì¸ êµ¬í˜„ì„ ìœ„í•´ DALL-E 3ë¥¼ ì‚¬ìš©í•˜ë˜, í”„ë¡¬í”„íŠ¸ì— 'Previous Image' ì •ë³´ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë„£ì„ ìˆœ ì—†ìŒ.
        # ë”°ë¼ì„œ ì—¬ê¸°ì„œëŠ” 'Anchor' ê°œë…ì„ í”„ë¡¬í”„íŠ¸ì— ê°•ë ¥í•˜ê²Œ ì£¼ì…í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ êµ¬í˜„í•©ë‹ˆë‹¤.
        # (OpenAI APIì˜ í•œê³„ë¡œ ì¸í•´, ì‹¤ì œ íŒŒì¼ ì—…ë¡œë“œ ê¸°ë°˜ì˜ ì¼ê´€ì„± ìœ ì§€ëŠ” ì•„ì§ ì œí•œì ì„)
        
        # í•˜ì§€ë§Œ ì‚¬ìš©ìê°€ 'images.edit'ì„ ì‚¬ìš©í•˜ëŠ” ì½”ë“œë¥¼ ë³´ì—¬ì¤¬ìœ¼ë¯€ë¡œ, 
        # DALL-E 2ë¥¼ ì‚¬ìš©í•˜ì—¬ editì„ ì‹œë„í•˜ê±°ë‚˜, 
        # DALL-E 3ë¡œ 'ìƒì„±'í•˜ë˜ í”„ë¡¬í”„íŠ¸ë¥¼ ê°•í™”í•˜ëŠ” ìª½ìœ¼ë¡œ ê°€ì•¼í•©ë‹ˆë‹¤.
        # ì—¬ê¸°ì„œëŠ” **Quality**ë¥¼ ìœ„í•´ DALL-E 3ë¥¼ ìœ ì§€í•˜ê³ , í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ìœ¼ë¡œ ì¼ê´€ì„±ì„ ì‹œë„í•©ë‹ˆë‹¤.
        
        response = client.images.generate(
            model="dall-e-3",
            prompt=consistent_prompt,
            size="1024x1024",
            quality="standard",
            n=1,
            response_format="b64_json"
        )
        
        image_data = base64.b64decode(response.data[0].b64_json)
        file_path = os.path.join(TEMP_DIR, f"scene_{scene_no}.png")
        
        with open(file_path, "wb") as f:
            f.write(image_data)
            
        print(f"âœ… [{scene_no}ë²ˆ ì”¬] ê·¸ë¦¼ ì™„ì„±!")
        return file_path
        
    except Exception as e:
        print(f"âŒ [{scene_no}ë²ˆ ì”¬] ê·¸ë¦¼ ì‹¤íŒ¨: {e}")
        return ""


# ==========================================
# 4. [ìŒí–¥íŒ€] TTS ìŒì„± ìƒì„± (ë¹„ë™ê¸°)
# ==========================================
async def generate_audio(text: str, scene_no: int):
    print(f"ğŸµ [{scene_no}ë²ˆ ì”¬] ì„±ìš° ë…¹ìŒ ì¤‘...")
    try:
        response = await aclient.audio.speech.create(
            model="tts-1", 
            voice="nova",  
            input=text
        )
        print(f"âœ… [{scene_no}ë²ˆ ì”¬] ë…¹ìŒ ì™„ì„±!")
        return {"scene_no": scene_no, "type": "audio", "data": response.read()}
    except Exception as e:
        print(f"âŒ [{scene_no}ë²ˆ ì”¬] ë…¹ìŒ ì‹¤íŒ¨: {e}")
        return {"scene_no": scene_no, "type": "audio", "data": None}


# ==========================================
# 5. [ê³µì¥ì¥] ìˆœì°¨ì  ê·¸ë¦¼ ìƒì„± & ë¹„ë™ê¸° ìŒì„± ìƒì„± í˜¼í•©
# ==========================================
async def generate_all_media_sequential(story_draft: StoryDraft):
    print("\nğŸš€ [ì‹œí€€ì…œ ê³µì¥ ê°€ë™] ê·¸ë¦¼ì€ ìˆœì„œëŒ€ë¡œ, ìŒì„±ì€ ë™ì‹œì— ë§Œë“­ë‹ˆë‹¤!")
    
    # 1. Anchor Image ìƒì„± (ë™ê¸°)
    anchor_path = generate_anchor_image(
        story_draft.anchor_prompt, 
        story_draft.style_guide, 
        story_draft.character_bible
    )
    
    media_results = []
    
    # 2. Scene Image ìˆœì°¨ ìƒì„± (Sequential)
    prev_image_path = None
    for scene in story_draft.scenes:
        # ê·¸ë¦¼ ìƒì„± (ìˆœì°¨)
        img_path = generate_scene_image_consistent(
            scene_no=scene.scene_no,
            scene_prompt=scene.image_prompt,
            style_guide=story_draft.style_guide,
            character_bible=story_draft.character_bible,
            anchor_path=anchor_path,
            prev_image_path=prev_image_path
        )
        
        # íŒŒì¼ ê²½ë¡œë¥¼ ê²°ê³¼ì— ë‹´ìŒ (ë‚˜ì¤‘ì— ì—…ë¡œë“œí•  ë•Œ ì½ìŒ)
        if img_path:
            with open(img_path, "rb") as f:
                img_bytes = f.read()
            media_results.append({"scene_no": scene.scene_no, "type": "image", "data": img_bytes})
            prev_image_path = img_path # ë‹¤ìŒ ì”¬ì„ ìœ„í•´ ê²½ë¡œ ì—…ë°ì´íŠ¸
        else:
            media_results.append({"scene_no": scene.scene_no, "type": "image", "data": None})

    # 3. Audio ìƒì„± (ë³‘ë ¬ - ë³€í™” ì—†ìŒ)
    audio_tasks = []
    for scene in story_draft.scenes:
        # ë‚´ë ˆì´ì…˜ + ëŒ€ì‚¬ í•©ì¹˜ê¸°
        full_text = scene.narrator_text + " " + " ".join(scene.dialogue)
        audio_tasks.append(generate_audio(full_text, scene.scene_no))
        
    audio_results = await asyncio.gather(*audio_tasks)
    media_results.extend(audio_results)
    
    print("ğŸ‰ [ê³µì¥ ì™„ë£Œ] ëª¨ë“  ë¯¸ë””ì–´ íŒŒì¼ ìƒì„± ë!\n")
    return media_results