import os
import asyncio
import base64
import tempfile
import uuid
import logging
from openai import OpenAI, AsyncOpenAI
from dotenv import load_dotenv
from schemas import StoryDraft

logger = logging.getLogger(__name__)

# ==========================================
# 0. í™˜ê²½ì„¤ì • ë° í´ë¼ì´ì–¸íŠ¸ ì¤€ë¹„
# ==========================================
load_dotenv() # .env íŒŒì¼ì—ì„œ API í‚¤ ë¶ˆëŸ¬ì˜¤ê¸°

# GPT í…ìŠ¤íŠ¸ ìƒì„± ë° DALL-E ì´ë¯¸ì§€ í¸ì§‘ìš© (ë™ê¸°ì‹ í´ë¼ì´ì–¸íŠ¸)
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# TTS ìŒì„± ìƒì„±ìš© (ë¹„ë™ê¸°ì‹ í´ë¼ì´ì–¸íŠ¸)
aclient = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))

TEXT_MODEL = os.getenv("OPENAI_TEXT_MODEL", "gpt-4o-mini")
IMAGE_MODEL = os.getenv("OPENAI_IMAGE_MODEL", "gpt-image-1.5")  # DALL-E 3ì—ì„œ ìµœì‹  ëª¨ë¸ë¡œ ë³€ê²½ ê¶Œì¥


# ==========================================
# 1. [ì´ê´„ ì…°í”„] GPT-4o ìŠ¤í† ë¦¬ & í€´ì¦ˆ ëŒ€ë³¸ ìƒì„± (Structured Outputs)
# ==========================================
def generate_story_draft(child_name: str, age: int, personality: str, emotion: str, source_text: str) -> StoryDraft:
    logger.info("\nâ³ [GPT-4o] ë™í™” ëŒ€ë³¸ ë° ìºë¦­í„° ì„¤ì • ìƒì„± ì¤‘...")
    
    system_prompt = f"""
    ë‹¹ì‹ ì€ {age}ì‚´ ì•„ì´ë“¤ì˜ ë§ˆìŒì„ ì½ì–´ì£¼ëŠ” ìµœê³ ì˜ ë§ì¶¤í˜• ë™í™” ì‘ê°€ì´ì êµìœ¡ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
    ì•„ì´ì˜ ì´ë¦„ì€ '{child_name}'ì´ê³ , ì„±í–¥ì€ '{personality}'ì´ë©°, í˜„ì¬ ê¸°ë¶„ì€ '{emotion}' ìƒíƒœì…ë‹ˆë‹¤.
    
    ì´ ì•„ì´ë¥¼ ë‹¬ë˜ì£¼ê¸° ìœ„í•´, ì•„ë˜ì˜ [í•™ìŠµ ê°œë…]ì„ ìì—°ìŠ¤ëŸ½ê²Œ ë…¹ì—¬ë‚¸ 5ì¥ì§œë¦¬ ë™í™”ì±… ëŒ€ë³¸ì„ ì‘ì„±í•˜ì„¸ìš”.
    
    [í•™ìŠµ ê°œë…]
    {source_text}
    
    [ì‘ì„± ê·œì¹™]
    1. ì£¼ì¸ê³µì˜ ì´ë¦„ì€ ë°˜ë“œì‹œ '{child_name}'ìœ¼ë¡œ í•˜ì„¸ìš”.
    2. ì´ 5ê°œì˜ ì”¬(scene)ìœ¼ë¡œ êµ¬ì„±í•˜ì„¸ìš”. 
    3. 3ë²ˆ ì”¬ê³¼ 5ë²ˆ ì”¬ì—ëŠ” ë°˜ë“œì‹œ [í•™ìŠµ ê°œë…]ê³¼ ê´€ë ¨ëœ í€´ì¦ˆ(quiz)ë¥¼ ë„£ìœ¼ì„¸ìš”. ë‚˜ë¨¸ì§€ ì”¬ì˜ quizëŠ” nullë¡œ ë¹„ì›Œë‘ì„¸ìš”.
    4. ê° ì”¬ë§ˆë‹¤ DALL-E 3ê°€ ê·¸ë¦¼ì„ ê·¸ë¦´ ìˆ˜ ìˆë„ë¡, 'image_prompt'ë¥¼ ìƒì„¸í•œ ì˜ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”. (ìˆ˜ì±„í™” í’ì˜ ë”°ëœ»í•œ ë™í™”ì±… ìŠ¤íƒ€ì¼ì„ ë¬˜ì‚¬í•  ê²ƒ)
    5. ëª¨ë“  ë™í™” ë‚´ìš©, ëŒ€ì‚¬, í€´ì¦ˆëŠ” ë°˜ë“œì‹œ 'í•œêµ­ì–´'ë¡œ ì‘ì„±í•˜ì„¸ìš”. (ë‹¨, DALL-Eë¥¼ ìœ„í•œ image_promptì™€ style_guide ë“±ì€ ë°˜ë“œì‹œ ì˜ì–´ë¡œ ì‘ì„±í•  ê²ƒ)
    6. ì¼ê´€ëœ ê·¸ë¦¼ ìƒì„±ì„ ìœ„í•´ 'style_guide', 'character_bible', 'anchor_prompt'ë¥¼ êµ¬ì²´ì ì¸ ì˜ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”.
    """

    # GPT-4o í˜¸ì¶œ (Structured Outputs ê¸°ëŠ¥ìœ¼ë¡œ JSON í‹€ ê°•ì œ)
    completion = client.beta.chat.completions.parse(
        model="gpt-4o-2024-08-06",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": "ê·œê²©ì— ë§ì¶°ì„œ ë™í™”ì±… JSON ë°ì´í„°ë¥¼ ìƒì„±í•´ì¤˜."}
        ],
        response_format=StoryDraft, 
    )

    story_draft = completion.choices[0].message.parsed
    logger.info(f"âœ… [GPT-4o] ëŒ€ë³¸ ìƒì„± ì™„ë£Œ! ì œëª©: {story_draft.title}")
    
    return story_draft


# ==========================================
# 2. [ë¯¸ìˆ  ê°ë…] ìºë¦­í„° ì‹œíŠ¸(Anchor Image) ìƒì„±
# ==========================================
def generate_anchor_image(anchor_prompt: str, style_guide: str, character_bible: str) -> str:
    logger.info("ğŸ¨ [Anchor] ìºë¦­í„° ì‹œíŠ¸(ê¸°ì¤€ ì´ë¯¸ì§€) ìƒì„± ì¤‘...")
    
    full_prompt = f"""
    {style_guide}
    {character_bible}
    {anchor_prompt}
    Important: Create a character reference sheet showing the full body and face clearly.
    """
    
    try:
        params = {
            "model": IMAGE_MODEL,
            "prompt": full_prompt,
            "size": "1024x1024",
            "quality": "high",
            "n": 1,
        }
        
        # ìµœì‹  GPT Image ëª¨ë¸ê³¼ ê¸°ì¡´ DALL-E ëª¨ë¸ íŒŒë¼ë¯¸í„° ë¶„ê¸°
        if "gpt-image" in IMAGE_MODEL:
            params["output_format"] = "png"
        else:
            params["response_format"] = "b64_json"

        response = client.images.generate(**params)
        
        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥ (OS ê¸°ë³¸ ì„ì‹œ í´ë” ì‚¬ìš©)
        item = response.data[0]
        b64 = item.b64_json if hasattr(item, "b64_json") and item.b64_json else item.b64
        image_data = base64.b64decode(b64)
        file_path = os.path.join(tempfile.gettempdir(), f"anchor_{uuid.uuid4().hex}.png")
        
        with open(file_path, "wb") as f:
            f.write(image_data)
            
        logger.info("âœ… [Anchor] ìºë¦­í„° ì‹œíŠ¸ ìƒì„± ì™„ë£Œ!")
        return file_path
        
    except Exception as e:
        logger.error(f"âŒ [Anchor] ìƒì„± ì‹¤íŒ¨: {e}")
        return ""


# ==========================================
# 3. [ë¯¸ìˆ íŒ€] ì¼ê´€ì„± ìˆëŠ” ì”¬ ì´ë¯¸ì§€ ìƒì„± (Sequential Editing)
# ==========================================
def generate_scene_image_consistent(scene_no: int, scene_prompt: str, style_guide: str, character_bible: str, anchor_path: str, prev_image_path: str = None) -> str:
    logger.info(f"ğŸ¨ [{scene_no}ë²ˆ ì”¬] ì¼ê´€ì„± ìˆëŠ” ê·¸ë¦¼ ê·¸ë¦¬ëŠ” ì¤‘...")
    
    # í”„ë¡¬í”„íŠ¸ ì¡°í•©
    consistent_prompt = f"""
    {style_guide}
    {character_bible}
    Continuity rules: Keep the protagonist's face, hair, and outfit colors exactly the same as the reference image.
    match the watercolor texture and linework style.
    
    Scene Description:
    {scene_prompt}
    """
    
    try:
        # ì•ˆì „í•œ íŒŒì¼ í•¸ë“¤ë§ì„ ìœ„í•´ ë¦¬ìŠ¤íŠ¸ ì¤€ë¹„
        image_files = [open(anchor_path, "rb")]
        try:
            if prev_image_path:
                image_files.append(open(prev_image_path, "rb"))
                
            # ëª¨ë¸ ì¢…ë¥˜ì— ë”°ë¼ íŒŒë¼ë¯¸í„° ë¶„ê¸° ì²˜ë¦¬
            params = {
                "model": IMAGE_MODEL,
                "image": image_files,
                "prompt": consistent_prompt,
                "n": 1,
                "size": "1024x1024",
                "quality": "high"
            }
            
            if "gpt-image" in IMAGE_MODEL:
                params["input_fidelity"] = "high" # ì›ë³¸ ìºë¦­í„° ìœ ì§€ìœ¨ ì¦ëŒ€
                params["output_format"] = "png"
            else:
                params["response_format"] = "b64_json"

            # ìµœì‹  ë‹¤ì¤‘ ì´ë¯¸ì§€ ê¸°ë°˜ edit ìˆ˜í–‰
            response = client.images.edit(**params)
            
            item = response.data[0]
            b64 = item.b64_json if hasattr(item, "b64_json") and item.b64_json else item.b64
            image_data = base64.b64decode(b64)
            file_path = os.path.join(tempfile.gettempdir(), f"scene_{scene_no}_{uuid.uuid4().hex}.png")
            
            with open(file_path, "wb") as f:
                f.write(image_data)
                
            logger.info(f"âœ… [{scene_no}ë²ˆ ì”¬] ê·¸ë¦¼ ì™„ì„±!")
            return file_path
            
        finally:
            # ì•ˆì „í•˜ê²Œ ì—´ì–´ë‘” íŒŒì¼ ê°ì²´ë“¤ì„ ëª¨ë‘ ë‹«ìŠµë‹ˆë‹¤ (ë©”ëª¨ë¦¬ ë¦­ ë° ê¶Œí•œ ì˜¤ë¥˜ ë°©ì§€)
            for f in image_files:
                try:
                    f.close()
                except Exception:
                    pass
                    
    except Exception as e:
        logger.error(f"âŒ [{scene_no}ë²ˆ ì”¬] ê·¸ë¦¼ ì‹¤íŒ¨: {e}")
        return ""


# ==========================================
# 4. [ìŒí–¥íŒ€] TTS ìŒì„± ìƒì„± (ë¹„ë™ê¸°)
# ==========================================
async def generate_audio(text: str, scene_no: int):
    logger.info(f"ğŸµ [{scene_no}ë²ˆ ì”¬] ì„±ìš° ë…¹ìŒ ì¤‘...")
    try:
        response = await aclient.audio.speech.create(
            model="gpt-4o-mini-tts", # ìµœì‹  ê³ í’ˆì§ˆ íš¨ìœ¨ ëª¨ë¸
            voice="alloy",  
            input=text
        )
        logger.info(f"âœ… [{scene_no}ë²ˆ ì”¬] ë…¹ìŒ ì™„ì„±!")
        return {"scene_no": scene_no, "type": "audio", "data": response.read()}
    except Exception as e:
        logger.error(f"âŒ [{scene_no}ë²ˆ ì”¬] ë…¹ìŒ ì‹¤íŒ¨: {e}")
        return {"scene_no": scene_no, "type": "audio", "data": None}


# ==========================================
# 5. [ê³µì¥ì¥] ìˆœì°¨ì  ê·¸ë¦¼ ìƒì„± & ë¹„ë™ê¸° ìŒì„± ìƒì„± í˜¼í•©
# ==========================================
async def generate_all_media_sequential(story_draft: StoryDraft):
    print("\nğŸš€ [ì‹œí€€ì…œ ê³µì¥ ê°€ë™] ê·¸ë¦¼ì€ ìˆœì„œëŒ€ë¡œ, ìŒì„±ì€ ë™ì‹œì— ë§Œë“­ë‹ˆë‹¤!")
    
    # 1. Anchor Image ìƒì„± (ë™ê¸°)
    anchor_path = generate_anchor_image(
        story_draft.anchor_prompt, 
        story_draft.style_guide, 
        story_draft.character_bible
    )
    
    media_results = []
    
    # 2. Scene Image ìˆœì°¨ ìƒì„± (Sequential)
    prev_image_path = None
    for scene in story_draft.scenes:
        # ê·¸ë¦¼ ìƒì„± (ìˆœì°¨)
        img_path = generate_scene_image_consistent(
            scene_no=scene.scene_no,
            scene_prompt=scene.image_prompt,
            style_guide=story_draft.style_guide,
            character_bible=story_draft.character_bible,
            anchor_path=anchor_path,
            prev_image_path=prev_image_path
        )
        
        # íŒŒì¼ ê²½ë¡œë¥¼ ê²°ê³¼ì— ë‹´ìŒ (ë‚˜ì¤‘ì— ì—…ë¡œë“œí•  ë•Œ ì½ìŒ)
        if img_path:
            with open(img_path, "rb") as f:
                img_bytes = f.read()
            media_results.append({"scene_no": scene.scene_no, "type": "image", "data": img_bytes})
            prev_image_path = img_path # ë‹¤ìŒ ì”¬ì„ ìœ„í•´ ê²½ë¡œ ì—…ë°ì´íŠ¸
        else:
            media_results.append({"scene_no": scene.scene_no, "type": "image", "data": None})

    # 3. Audio ìƒì„± (ë³‘ë ¬ - ë³€í™” ì—†ìŒ)
    audio_tasks = []
    for scene in story_draft.scenes:
        # ë‚´ë ˆì´ì…˜ ëŒ€ì‚¬ ì‚¬ìš©
        audio_tasks.append(generate_audio(scene.text, scene.scene_no))
        
    audio_results = await asyncio.gather(*audio_tasks)
    media_results.extend(audio_results)
    
    print("ğŸ‰ [ê³µì¥ ì™„ë£Œ] ëª¨ë“  ë¯¸ë””ì–´ íŒŒì¼ ìƒì„± ë!\n")
    return media_results